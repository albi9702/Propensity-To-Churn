---
title: "Script Digital Marketing"
author: "Alberto Filosa"
date: "17/8/2020"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r Setup e Librerie, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      fig.align = "center",
                      out.width = "60%",
                      dev = "svg",
                      dpi = 36)

#-- Libraries
library(tidyverse)
library(dplyr)
library(magrittr)
library(ggplot2)
library(forcats)
library(lubridate)
library(RQuantLib)
library(caret)
library(rpart)
library(rpart.plot)
library(MLmetrics)
library(randomForest)
library(glmnet)
library(LiblineaR)
library(funModeling)
library(arulesViz)

load("objects.RData")

set.seed(123456) #-- Set seed for same results

data_dir <- "G:\\Il mio Drive\\Università\\Data Science\\1° Anno\\Web Marketing and Communication Management\\Esame\\Dataset"
```

# Reading Files

## Dataset 1
`raw_1_cli_fid.csv` contains info on the fidelty subscriptions of each costumer account:

* `ID_CLI`: identify client (*Foreign Key*);
* `ID_FID`: identify fidelty program (**Key**);
* `ID_NEG`: identify reference stoe;
* `TYP_CLI_FID`: identify the main account (Binomyal);
* `COD_FID`: identify the fidelty program;
* `STATUS_FID`: identify if an account is active (Binomyal);
* `DT_ACTIVE`: identify the date of activation.

```{r Reading File 1, results = 'asis'}
#-- Changed name `df_1_cli_fid` in fidelity
fidelity <- read_csv2(file.path(data_dir, "raw_1_cli_fid.csv"), #-- Directory
                          na = c("NA", ""))                     #-- Identify Missing Values

knitr::kable(head(fidelity))    #-- First 5 rows
summary(fidelity)               #-- Descriptive Analysis
```

## Dataset 2
`raw_2_cli_account.csv` contains info on each customer account:

* `ID_CLI`: identify the client (**Key**);
* `EMAIL_PROVIDER`: identify the email account provider;
* `W_PHONE`: identify if a phone number is added (Binomyal);
* `ID_ADDRESS`: identify the address (*Foreign Key*);
* `TYP_CLI_ACCOUNT`: identify the account type of the client;
* `TYP_JOB`: identify the client job.

```{r Reading File 2}
#-- Changed name `df_2_cli_account` in account
account <- read_csv2(file.path(data_dir, "raw_2_cli_account.csv"), #-- Directory
                              na = c("NA", ""))                    #-- Identify Missing Values

knitr::kable(head(account))    #-- First 5 rows
summary(account)               #-- Descriptive Analysis
```

## Dataset 3
`raw_3_cli_address.csv` contains information on the address corresponding to a customer account:

* `ID_ADDRESS`: identify the address (**Key**);
* `CAP`: identify the postal code;
* `PRV`: identify the province;
* `REGION`: identify the region.

```{r Reading File 3}
#-- Changed name `df_3_cli_address` in address
address <- read_csv2(file.path(data_dir, "raw_3_cli_address.csv"), #-- Directory
                              na = c(""))                          #-- Identify Missing Values

knitr::kable(head(address))    #-- First 5 rows
summary(address)               #-- Descriptive Analysis
```

## Dataset 4
`raw_4_cli_privacy.csv` contains information on the privacy policies accepted by each customer:

* `ID_CLI`: identify the client (*Foreign Key*);
* `FLAG_PRIVACY_1`: identify the flag privacy (binomyal);
* `FLAG_PRIVACY_2`: identify the flag profiling (*Foreign Key*);
* `FLAG_DIRECT_MKT`: identify the flag direct marketing (binomyal).

```{r Reading File 4}
#-- Changed name `df_4_cli_privacy` in privacy
privacy <- read_csv2(file.path(data_dir, "raw_4_cli_privacy.csv"), #-- Directory
                              na = c("NA", ""))                    #-- Identify Missing Values

knitr::kable(head(privacy))    #-- First 5 rows
summary(privacy)               #-- Descriptive Analysis
```

## Dataset 5
`raw_5_camp_cat.csv` contains the categorization of the marketing email communications:

* `ID_CAMP`: identify the email campaign (**Key**);
* `TYP_CAMP`: identify the type email campaign.

```{r Reading File 5}
#-- Changed name `df_5_camp_cat` in campaign_category
campaign_category <- read_csv2(file.path(data_dir, "raw_5_camp_cat.csv"), #-- Directory
                           na = c("NA", ""))                              #-- Identify Missing Values

knitr::kable(head(campaign_category))    #-- First 5 rows
summary(campaign_category)               #-- Descriptive Analysis
```

## Dataset 6
`raw_6_camp_event.csv` contains the events (sents, opens and clicks) related to the marketing email communications:

* `ID_EVENT`: identify the feedback event (**Key**);
* `ID_CLI`: identify the client (*Foreign Key*);
* `ID_CAMP`: identify the email campaign (*Foreign Key*);
* `ID_DELIVERY`: identify the delivery;
* `TYP_EVENT`: identify the feedback event:
    + S = Send;
    + V = Open;
    + C = Click;
    + B = Bounce;
    + E = Error;
* `EVENT_DATE`: identify the datetime event.

```{r Reading File 6}
#-- Changed name `df_6_camp_event` in campaign_event
campaign_event <- read_csv2(file.path(data_dir, "raw_6_camp_event.csv"), #-- Directory
                             na = c("NA", ""))                           #-- Identify Missing Values

knitr::kable(head(campaign_event))    #-- First 5 rows
summary(campaign_event)               #-- Descriptive Analysis
```

## Dataset 7
`raw_7_tic.csv` contains the purchase and refund transaction of each customer:

* `ID_SCONTRINO`: identify the transaction (all products have same ID);
* `ID_CLI`: identify the client (*Foreign Key*);
* `ID_NEG`: identify the reference store (*Foreign Key*);
* `ID_ARTICOLO`: identify the purchased or refund item;
* `COD_REPARTO`: identify the business unit corresponding to the item;
* `DIREZIONE`: identify the purchase (1) or refund (-1);
* `IMPORTO_LORDO`: identify the gross amount as the sum of net amount and the discount applied;
* `SCONTO`: identify the discount applied (negative if refund);
* `DATETIME`: datetime of the transaction.

```{r Reading File 7}
#-- Changed name `df_7_tic` in tickets
tickets <- read_csv2(file.path(data_dir, "raw_7_tic.csv"), #-- Directory
                      na = c("NA", ""))                    #-- Identify Missing Values
                      
knitr::kable(head(tickets))    #-- First 5 rows
summary(tickets)               #-- Descriptive Analysis
```

# Cleaning Files

First of all, it is reccomended to create a copy for all datasets before data manipulation: 

```{r Copy Files}
fidelity_clean <- fidelity          #-- Dataset 1
account_clean  <- account           #-- Dataset 2
address_clean  <- address           #-- Dataset 3
privacy_clean  <- privacy           #-- Dataset 4
campaign_category_clean <- campaign_category #-- Dataset 5
campaign_event_clean    <- campaign_event    #-- Dataset 6
tickets_clean  <- tickets           #-- Dataset 7
```

## 1. Fidelity

First, we check if there are some duplicate rows:

```{r Duplicates Fidelity}
fidelity_clean_duplicate <- fidelity_clean %>%
                              summarize(TOT_ID_CLIs = n_distinct(ID_CLI), #-- Number of Total Clients
                              TOT_ID_FIDs = n_distinct(ID_FID),           #-- Number of Total Fidelity Program
                              TOT_ID_CLIFIDs = n_distinct(paste0(as.character(ID_CLI), "-",
                                                                 as.character(ID_FID))),
                              TOT_ROWs = n())                             #-- Number of Total Rows

knitr::kable(fidelity_clean_duplicate)
```

```{r Manipulation Fidelity}
fidelity_clean <- fidelity_clean                                 %>% 
                    mutate(DT_ACTIVE = as.Date(DT_ACTIVE))       %>% #-- Formatting dates 
                    mutate(TYP_CLI_FID = as.factor(TYP_CLI_FID)) %>% #-- Factorize TYP_CLI_FID
                    mutate(STATUS_FID = as.factor(STATUS_FID))       #-- Factorize STATUS_FID
```

Check the number of fidelity subscriptions per client:

```{r Fidelity Subscriptions 1, eval = FALSE}
num_fid_x_cli <- fidelity_clean     %>%
                   group_by(ID_CLI) %>%                         #-- Group by Client
                   summarize(NUM_FIDs  = n_distinct(ID_FID),    #-- Distinct Fidelity
                             NUM_DATEs = n_distinct(DT_ACTIVE)) #-- Distinct Date
```


```{r Fidelity Subscriptions 2}
tot_id_cli <- n_distinct(num_fid_x_cli$ID_CLI)

dist_num_fid_x_cli <- num_fid_x_cli %>%
                        group_by(NUM_FIDs, NUM_DATEs)            %>% #-- Group by Client & Date of Activation
                        summarize(TOT_CLIs = n_distinct(ID_CLI)) %>% #-- Total Clients
                        mutate(PERCENT_CLIs = TOT_CLIs/tot_id_cli)   #-- Percentage

knitr::kable(dist_num_fid_x_cli)
```

Note that there are clients with multiple fidelity subscriptions. In details, let examine clients with multiple subscriptions:

```{r Multiple Fidelity}
num_fid_x_cli %>%
  filter(NUM_FIDs == 3)

fidelity_clean %>%
  filter(ID_CLI == 621814)

fidelity_clean %>%
  filter(ID_CLI == 320880)
```

After, we combine the information for each client from first subscription (registration date and store for registration) to the last (type of fidelity and status):

```{r Info Combined Fidelity, eval = FALSE}
client_fidelity_first <- fidelity_clean                        %>%
                           group_by(ID_CLI)                    %>% #-- Grouped by Client ID
                           filter(DT_ACTIVE == min(DT_ACTIVE)) %>% #-- Filtered by min DT_ACTIVE
                           arrange(ID_FID)                     %>% #-- Sorted by client ID
                           filter(row_number() == 1)           %>% #-- Filter Row #1
                           ungroup()                           %>% 
                           as.data.frame()

client_fidelity_last <- fidelity_clean                        %>%
                          group_by(ID_CLI)                    %>% #-- Grouped by Client ID
                          filter(DT_ACTIVE == max(DT_ACTIVE)) %>% #-- Filtered by max DT_ACTIVE
                          arrange(desc(ID_FID))               %>% #-- Sorted by client ID
                          filter(row_number() == 1)           %>% #-- Filter Row #1
                          ungroup()                           %>%
                          as.data.frame()
```

We left join `client_fidelity_first` and `num_fid_x_cli` in `df_1_cli_fid_last`: 

```{r Left Join Fidelity}
fidelity_clean <- client_fidelity_last                      %>%
                      select(ID_CLI,
                             ID_FID,
                             LAST_COD_FID = COD_FID,
                             LAST_TYP_CLI_FID = TYP_CLI_FID,
                             LAST_STATUS_FID = STATUS_FID,
                             LAST_DT_ACTIVE = DT_ACTIVE)    %>% #-- Selection of Variables
                      left_join(client_fidelity_first       %>% #-- Left Join with client_fidelity_first
                                  select(ID_CLI,
                                         FIRST_ID_NEG = ID_NEG,
                                         FIRST_DT_ACTIVE = DT_ACTIVE),
                                by = "ID_CLI")              %>%
                      left_join(num_fid_x_cli         %>%       #-- Left Join with num_fid_x_cli
                                  select(ID_CLI,
                                         NUM_FIDs)          %>%
                                  mutate(NUM_FIDs = as.factor(NUM_FIDs)),
                                by = "ID_CLI")
```

### Exploration Analysis
First, it's necessary to compute the distribution of the fidelity program:

```{r Distribution LAST_COD_FID Fidelity}
df1_dist_codfid <- fidelity_clean          %>%
  group_by(LAST_COD_FID)                   %>% #-- Grouped by Fidelty Program
  summarize(TOT_CLIs = n_distinct(ID_CLI)) %>% #-- Number of Total Client
  mutate(PERCENT = TOT_CLIs/sum(TOT_CLIs)) %>% #-- Percent
  arrange(desc(PERCENT))                       #-- Sort by Percent decreasing

knitr::kable(df1_dist_codfid)

ggplot(data = df1_dist_codfid,
       aes(x = LAST_COD_FID, y = TOT_CLIs)) +  #-- Dataset to Plot
  geom_bar(stat = "identity",                  
           fill = "steelblue") +               #-- Bar Plot
  theme_minimal()                              #-- ggplot Theme
```

Let's explore the status variable (`LAST_STATUS_FID`):

```{r Distribution LAST_STATUS_FID Fidelity}
df1_dist_status <- fidelity_clean          %>% 
  group_by(LAST_STATUS_FID)                %>%   #-- Grouped by Active Account
  summarize(TOT_CLIs = n_distinct(ID_CLI)) %>%   #-- Number of Total Client
  mutate(PERCENT = TOT_CLIs/sum(TOT_CLIs)) %>%   #-- Percent
  arrange(desc(PERCENT))                         #-- Sort by Percent decreasing


ggplot(data = df1_dist_status, 
       aes(x = LAST_STATUS_FID, y = TOT_CLIs)) + #-- Dataset to Plot
  geom_bar(stat = "identity",                 
           fill = "steelblue") +                 #-- Bar Plot
  theme_minimal()                                #-- ggplot Theme
```

Let's explore the fidelity card variable (`NUM_FIDs`):

```{r Distribution NUM_FIDs Fidelity}
df1_dist_num <- fidelity_clean             %>%
  group_by(NUM_FIDs)                       %>% #-- Grouped by Fidelity Program
  summarize(TOT_CLIs = n_distinct(ID_CLI)) %>% #-- Number of Total Client
  mutate(PERCENT = TOT_CLIs/sum(TOT_CLIs)) %>% #-- Percent
  arrange(desc(PERCENT))                       #-- Sort by Percent decreasing

ggplot(data = df1_dist_num,               
       aes(x = NUM_FIDs, y = TOT_CLIs)) +      #-- Dataset to Plot
  geom_bar(stat = "identity",
           fill = "steelblue") +               #-- Bar Plot
  theme_minimal()                              #-- ggplot Theme
```

Let's explore the last fidelity card variable (`LAST_TYP_CLI_FID`):

```{r Distribution LAST_TYP_CLI_FID Fidelity}
df1_dist_type <- fidelity_clean            %>%
  group_by(LAST_TYP_CLI_FID)               %>%    #-- Grouped by Main Account
  summarize(TOT_CLIs = n_distinct(ID_CLI)) %>%    #-- Number of Total Client
  mutate(PERCENT = TOT_CLIs/sum(TOT_CLIs)) %>%    #-- Percent
  arrange(desc(PERCENT))                          #-- Sort by Percent decreasing

ggplot(data = df1_dist_type,
       aes(x = LAST_TYP_CLI_FID, y = TOT_CLIs)) + #-- Dataset to Plot
  geom_bar(stat = "identity",
           fill = "steelblue") +                  #-- Bar Plot
  theme_minimal()                                 #-- ggplot Theme
```

Let's explore the date of activation card variable (`FIRST_DT_ACTIVE`):

```{r Distribution FIRST_DT_ACTIVE Fidelity}
df1_dist_date <- fidelity_clean            %>%
  group_by(FIRST_DT_ACTIVE)                %>%   #-- Grouped by Date of Activation
  summarize(TOT_CLIs = n_distinct(ID_CLI)) %>%   #-- Number of Total Client
  mutate(PERCENT = TOT_CLIs/sum(TOT_CLIs)) %>%   #-- Percent
  arrange(desc(PERCENT))                         #-- Sort by Percent decreasing

ggplot(data = df1_dist_date,
       aes(x = FIRST_DT_ACTIVE, y = TOT_CLIs)) + #-- Dataset to Plot
  geom_line() +                                  #-- Bar Plot
  theme_minimal()                                #-- ggplot Theme
```

## 2. Account

We check for duplicate rows:

```{r Duplicated Account}
account_clean_duplicate <- account_clean %>%
                            summarize(TOT_ID_CLIs = n_distinct(ID_CLI),
                                      TOT_ROWs = n())
                          
knitr::kable(account_clean_duplicate) #-- No Duplicated rows
```

```{r Manipulation Account}
account_clean <- account_clean %>%
                  mutate(W_PHONE = as.factor(W_PHONE))                  %>% #-- Factorized
                  mutate(TYP_CLI_ACCOUNT = as.factor(TYP_CLI_ACCOUNT))  %>% #-- Factorized 
                  mutate(W_PHONE = fct_explicit_na(W_PHONE, "0"))       %>% #-- Missing Values
                  mutate(EMAIL_PROVIDER = fct_explicit_na(EMAIL_PROVIDER,
                                                          "(missing)")) %>% #-- NA with Categorial
                  mutate(TYP_JOB = fct_explicit_na(TYP_JOB, "(missing)"))   #-- NA with Categorial
```

### Reshaping

```{r Email Provider Account}
df_2_dist_emailprovider <- account_clean                             %>%
                            group_by(EMAIL_PROVIDER)                 %>% #-- Group by EMAIL_PROVIDER
                            summarize(TOT_CLIs = n_distinct(ID_CLI)) %>% #-- Number of Total Client
                            mutate(PERCENT = TOT_CLIs/sum(TOT_CLIs)) %>% #-- Percent
                            arrange(desc(PERCENT))                   %>% #-- Sorted by PERCENt
                            as.data.frame()

knitr::kable(head(df_2_dist_emailprovider))
```

There are `r n_distinct(df_2_dist_emailprovider$EMAIL_PROVIDER)`: too many different values for `EMAIL_PROVIDER` to be an useful category. We keep the most frequent email provider values and add a common factor level `other` for the remaining:

```{r Reshape Email Provider Account}
knitr::kable(df_2_dist_emailprovider                       %>%
  arrange(desc(PERCENT))                                   %>% #-- Sorted by PERCENt
  mutate(PERCENT_COVERED = cumsum(TOT_CLIs)/sum(TOT_CLIs)) %>% #-- Percent
  as.data.frame()                                          %>%
  head(10))

clean_email_providers <- df_2_dist_emailprovider %>%
                          arrange(desc(PERCENT)) %>%                                        #-- Sorted by PERCENt
                          mutate(PERCENT_COVERED = cumsum(TOT_CLIs)/sum(TOT_CLIs)) %>%      #-- Percent
                          mutate(EMAIL_PROVIDER = as.character(EMAIL_PROVIDER))    %>%
                          mutate(AUX = if_else(PERCENT_COVERED < 0.85 |
                                                 (PERCENT_COVERED > 0.85 &
                                                    lag(PERCENT_COVERED) < 0.85), 1,0)) %>% #-- Percent Covered
                          mutate(EMAIL_PROVIDER_CLEAN = if_else(AUX | EMAIL_PROVIDER == "(missing)",
                                                                EMAIL_PROVIDER,
                                                                "others"))                  #-- Others if Missing

knitr::kable(head(clean_email_providers, 7))

account_clean <- account_clean                          %>%
  mutate(EMAIL_PROVIDER = as.character(EMAIL_PROVIDER)) %>% #-- EMAIL_PROVIDER as Character
  left_join(clean_email_providers                       %>%
              select(EMAIL_PROVIDER, EMAIL_PROVIDER_CLEAN),
            by = "EMAIL_PROVIDER")                      %>% #-- Left Join with clean_email_providers
  select(-EMAIL_PROVIDER)                               %>%
  mutate(EMAIL_PROVIDER_CLEAN = as.factor(EMAIL_PROVIDER_CLEAN)) #-- Factorized
```

```{r Phone Distribution Account}
df_2_dist_phone <- account_clean %>%
  group_by(W_PHONE)                        %>% #-- Grouped By W_PHONE
  summarize(TOT_CLIs = n_distinct(ID_CLI)) %>% #-- Number of Total Client
  mutate(PERCENT = TOT_CLIs/sum(TOT_CLIs)) %>% #-- Percent
  arrange(desc(PERCENT))                   %>% #-- Sorted by PERCENT
  as.data.frame()

knitr::kable(df_2_dist_phone)
```

```{r Type Account Distribution Account}
df_2_dist_account <- account_clean         %>%
  group_by(TYP_CLI_ACCOUNT)                %>% #-- Grouped By TYP_CLI_ACCOUNT
  summarize(TOT_CLIs = n_distinct(ID_CLI)) %>% #-- Number of Total Client
  mutate(PERCENT = TOT_CLIs/sum(TOT_CLIs)) %>% #-- Percent
  arrange(desc(PERCENT))                   %>% #-- Sorted by PERCENT
  as.data.frame()

knitr::kable(df_2_dist_account)
```

### Exploration Analysis

Let's explore the email provider for each client (`EMAIL_PROVIDER_CLEAN`):

```{r Distribution EMAIL_PROVIDER_CLEAN Account}
df2_dist_emailproviderclean <- account_clean %>%
  group_by(EMAIL_PROVIDER_CLEAN)             %>% #-- Grouped By EMAIL_PROVIDER_CLEAN
  summarize(TOT_CLIs = n_distinct(ID_CLI))   %>% #-- Number of Total Client
  mutate(PERCENT = TOT_CLIs/sum(TOT_CLIs))   %>% #-- Percent
  arrange(desc(PERCENT))                         #-- Sorted by PERCENT 

ggplot(data = df2_dist_emailproviderclean,
       aes(x = EMAIL_PROVIDER_CLEAN,
           y = TOT_CLIs)) +                      #-- Dataset to Plot
  geom_bar(stat = "identity",
           fill = "steelblue") +                 #-- Bar Plot
  theme_minimal()                                #-- ggplot Theme
```

Let's explore the type job for each client (`TYP_JOB`):

```{r Distribution TYP_JOB Account}
df_2_dist_job <- account_clean             %>%
  group_by(TYP_JOB)                        %>% #-- Grouped By TYP_JOB
  summarize(TOT_CLIs = n_distinct(ID_CLI)) %>% #-- Number of Total Client
  mutate(PERCENT = TOT_CLIs/sum(TOT_CLIs)) %>% #-- Percent
  arrange(desc(PERCENT))                   %>% #-- Sorted by PERCENT 
  as.data.frame()

knitr::kable(df_2_dist_job)

ggplot(data = df_2_dist_job,
       aes(x = TYP_JOB,
           y = TOT_CLIs)) +                    #-- Dataset to Plot
  geom_bar(stat = "identity", 
           fill = "steelblue") +               #-- Bar Plot
  theme_minimal()                              #-- ggplot Theme
```

Let's explore the type account for each client (`TYP_CLI_ACCOUNT`):

```{r Distribution TYP_CLI_ACCOUNT Account}
df_2_dist_account <- account_clean         %>%
  group_by(TYP_CLI_ACCOUNT)                %>% #-- Grouped By TYP_CLI_ACCOUNT
  summarize(TOT_CLIs = n_distinct(ID_CLI)) %>% #-- Number of Total Client
  mutate(PERCENT = TOT_CLIs/sum(TOT_CLIs)) %>% #-- Percent
  arrange(desc(PERCENT))                   %>% #-- Sorted by PERCENT 
  as.data.frame()

knitr::kable(df_2_dist_account)

ggplot(data = df_2_dist_phone,
       aes(x = W_PHONE,
           y = TOT_CLIs)) +                    #-- Dataset to Plot
  geom_bar(stat = "identity",
           fill = "steelblue") +               #-- Bar Plot
  theme_minimal()                              #-- ggplot Theme
```

## 3. Address

We check for duplicate rows:

```{r Duplicated Address}
knitr::kable(address_clean %>%
               summarize(TOT_ID_ADDRESSes = n_distinct(ID_ADDRESS), #-- Total of Addresses
               TOT_ROWs = n()))                                     #-- Total Rows

#-- Remove Duplicates
address_clean <- address_clean %>%
                  distinct()
```

Let's manipulate missing values:

```{r Manipulation Address}
address_clean <- address_clean %>%
                    mutate(CAP = as.character(CAP))                   %>% #-- Factorized
                    filter(!is.na(CAP) & !is.na(PRV) & !is.na(REGION))
```

### Explanatory Analysis

Let's explore the CAP address (`CAP`):

```{r Distribution CAP Address}
nrow(address_clean %>%
  distinct(CAP))       #-- Number of CAP
```

There are `r nrow(address_clean %>% distinct(CAP))`: too many to plot.

Let's explore the province address (`PRV`):

```{r Distribution Province Address}
nrow(address_clean %>%
  distinct(PRV))       #-- Number of Provinces
```

There are `r nrow(address_clean %>% distinct(PRV))`: too many to plot.

Let's explore the region for each client (`REGION`):

```{r Distribution REGION Address}
df3_dist_region<- address_clean                   %>%
  group_by(REGION)                                %>%  #-- Grouped By REGION
  summarize(TOT_ADDRESS = n_distinct(ID_ADDRESS)) %>%  #-- Number of Total Client
  mutate(PERCENT = TOT_ADDRESS/sum(TOT_ADDRESS))  %>%  #-- Percent
  arrange(desc(PERCENT))                               #-- Sorted by PERCENT 

knitr::kable(head(df3_dist_region))

ggplot(data = df3_dist_region, aes(x = REGION,
                                   y = TOT_ADDRESS)) + #-- Dataset to Plot
  geom_bar(stat = "identity",
           fill = "steelblue") +                       #-- Bar Plot
  theme_minimal()                                      #-- ggplot Theme
```

## 4. Privacy

We check for duplicate rows:

```{r Duplicate Privacy}
knitr::kable(privacy_clean %>%
               summarize(TOT_ID_CLIs = n_distinct(ID_CLI), #-- Total Client
               TOT_ROWs = n()))                            #-- No Duplicated rows
```

Let's manipulate the privacy dataset:

```{r Manipulation Privacy}
privacy_clean <- privacy_clean                       %>%
  mutate(FLAG_PRIVACY_1 = as.factor(FLAG_PRIVACY_1)) %>% #-- Factorized
  mutate(FLAG_PRIVACY_2 = as.factor(FLAG_PRIVACY_2)) %>% #-- Factorized
  mutate(FLAG_DIRECT_MKT = as.factor(FLAG_DIRECT_MKT))   #-- Factorized
```

### Explanatory Analysis

Let's explore the first privacy method (FLAG_PRIVACY_1):

```{r Dsitribution FLAG_PRIVACY_1 Address}
df4_dist_privacy1<- privacy_clean                            %>%
                      group_by(FLAG_PRIVACY_1)               %>% #-- Grouped By FLAG_PRIVACY_1
                      summarize(TOT_ID = n_distinct(ID_CLI)) %>% #-- Number of Total Client
                      mutate(PERCENT = TOT_ID/sum(TOT_ID))   %>% #-- Percent
                      arrange(desc(PERCENT))                     #-- Sorted by PERCENT 

knitr::kable(df4_dist_privacy1)

ggplot(data = df4_dist_privacy1,
       aes(x = FLAG_PRIVACY_1,
           y = TOT_ID)) +        #-- Data to Plot
  geom_bar(stat = "identity",
           fill = "steelblue") + #-- Bar Plot
  theme_minimal()                #-- ggplot Theme
```

Let's explore the second privacy method (FLAG_PRIVACY_2):

```{r Dsitribution FLAG_PRIVACY_2 Address}
df4_dist_privacy2 <- privacy_clean                            %>%
                      group_by(FLAG_PRIVACY_2)                %>% #-- Grouped By FLAG_PRIVACY_1
                      summarize(TOT_ID = n_distinct(ID_CLI))  %>% #-- Number of Total Client
                      mutate(PERCENT = TOT_ID/sum(TOT_ID))    %>% #-- Percent
                      arrange(desc(PERCENT))                      #-- Sorted by PERCENT 

knitr::kable(df4_dist_privacy2)

ggplot(data = df4_dist_privacy2,
       aes(x = FLAG_PRIVACY_2,
           y = TOT_ID)) +        #-- Data to Plot
  geom_bar(stat = "identity",
           fill = "steelblue") + #-- Bar Plot
  theme_minimal()                #-- ggplot Theme
```

Let's explore the privacy MTK method (FLAG_DIRECT_MKT):

```{r Dsitribution FLAG_DIRECT_MKT Address}
df4_dist_privacy_mkt <- privacy_clean                             %>%
                          group_by(FLAG_DIRECT_MKT)               %>% #-- Grouped By FLAG_PRIVACY_1
                          summarize(TOT_ID = n_distinct(ID_CLI))  %>% #-- Number of Total Client
                          mutate(PERCENT = TOT_ID/sum(TOT_ID))    %>% #-- Percent
                          arrange(desc(PERCENT))                      #-- Sorted by PERCENT 

knitr::kable(df4_dist_privacy_mkt)

ggplot(data = df4_dist_privacy_mkt,
       aes(x = FLAG_DIRECT_MKT,
           y = TOT_ID)) +        #-- Data to Plot
  geom_bar(stat = "identity",
           fill = "steelblue") + #-- Bar Plot
  theme_minimal()                #-- ggplot Theme
```

## 5. Campaign Category

The campaign channel (`CHANNEL_CAMP`) is not importants: let's remove it.

```{r Manipulation Campaign Category}
campaign_category_clean <- campaign_category_clean %>%
                             select(-CHANNEL_CAMP)
```

## 6. Campaign Event

Let's format dates and times:

```{r Manipulation Campaign Event}
campaign_event_clean <- campaign_event_clean                                                    %>%
                              mutate(EVENT_DATETIME = as.POSIXct(EVENT_DATE,
                                                                 format = "%Y-%m-%dT%H:%M:%S")) %>% #-- Formatting Dates
                              mutate(EVENT_HOUR = hour(EVENT_DATETIME))                         %>% #-- Hours
                              mutate(EVENT_DATE = as.Date(EVENT_DATETIME))                          #-- As Date
```

### Reshaping

We remap the event type values `E` (*ERROR*) and `B` [*BOUNCE*] into a level `F` [*FAILURE*]:

```{r Remap TYP_EVENT Campaign Event}
campaign_event_clean <- campaign_event_clean %>%
                          mutate(TYP_EVENT = as.factor(if_else(TYP_EVENT == "E" | TYP_EVENT == "B",
                                                               "F", as.character(TYP_EVENT)))) %>%  #-- Remapping Values
                          left_join(campaign_category_clean,
                                    by = "ID_CAMP")                                                 #-- Left Join

```

Also, is necessary to organize the data adding to each sending event the corresponding opens/clicks/fails:

```{r Sends Campaign Event}
df_sends <- campaign_event_clean             %>%
              filter(TYP_EVENT == "S")       %>% #-- Filter Sends
              select(-TYP_EVENT)             %>%
              select(ID_EVENT_S = ID_EVENT,
                     ID_CLI,
                     ID_CAMP,
                     TYP_CAMP,
                     ID_DELIVERY,
                     SEND_DATE = EVENT_DATE) %>% #-- Variable Selection
              as.data.frame()
```

There could be multiple opens of the same communication:

1. Count the open events;
2. Consider explicitely only the first open.

```{r Open Campaign Event, eval = FALSE}
df_opens_prep <- campaign_event_clean              %>%
                    filter(TYP_EVENT == "V")       %>% #-- Filter Sends
                    select(-TYP_EVENT)             %>%
                    select(ID_EVENT_O = ID_EVENT,
                           ID_CLI,
                           ID_CAMP,
                           TYP_CAMP,
                           ID_DELIVERY,
                           OPEN_DATETIME = EVENT_DATETIME,
                           OPEN_DATE = EVENT_DATE) %>% #-- Variable Selection
                    as.data.frame()

total_opens <- df_opens_prep                                  %>%
                  group_by(ID_CLI,
                           ID_CAMP,
                           ID_DELIVERY)                       %>% #-- Grouped By Client, Campaign & Delivery
                  summarize(NUM_OPENs = n_distinct(ID_EVENT_O))   #-- Number of Total Mail Opened
                
df_opens <- df_opens_prep                                 %>%
              left_join(total_opens,
                        by = c("ID_CLI",
                               "ID_CAMP",
                               "ID_DELIVERY"))            %>% #-- Left join with total_opens
              group_by(ID_CLI,
                       ID_CAMP,
                       ID_DELIVERY)                       %>% #-- Grouped By Client, Campaign & Delivery
              filter(OPEN_DATETIME == min(OPEN_DATETIME)) %>% #-- Filter By Min Mail Opened
              filter(row_number() == 1)                   %>%
              ungroup()                                   %>%
              as.data.frame()
```

There could be multiple clicks of the same communication:

1. Count the click events;
2. Consider explicitely only the first click.

```{r Clicks Campaign Event, eval = FALSE}
df_clicks_prep <- campaign_event_clean                              %>%
                      filter(TYP_EVENT == "C")                      %>% #-- Filter By Clicks
                      select(-TYP_EVENT)                            %>%
                      select(ID_EVENT_C = ID_EVENT,
                             ID_CLI,
                             ID_CAMP,
                             TYP_CAMP,
                             ID_DELIVERY,
                             CLICK_DATETIME = EVENT_DATETIME,
                             CLICK_DATE = EVENT_DATE)                   #-- Variable Selection
                    
total_clicks <- df_clicks_prep                                    %>%
                    group_by(ID_CLI,
                             ID_CAMP,
                             ID_DELIVERY)                         %>% #-- Grouped By Client, Campaign & Delivery
                    summarize(NUM_CLICKs = n_distinct(ID_EVENT_C))    #-- Number of Total Clicks

df_clicks <- df_clicks_prep                                   %>%
                left_join(total_clicks,
                          by = c("ID_CLI",
                                 "ID_CAMP",
                                 "ID_DELIVERY"))              %>% #-- Left Join with total_clicks
                group_by(ID_CLI,
                         ID_CAMP,
                         ID_DELIVERY)                         %>% #-- Grouped By Client, Campaign & Delivery
                filter(CLICK_DATETIME == min(CLICK_DATETIME)) %>% #-- Filter By Min Mail Clicked
                filter(row_number() == 1) %>%
                ungroup()                                     %>%
                as.data.frame()
```

```{r Fails Campaign Event}
df_fails <- campaign_event_clean                          %>%
              filter(TYP_EVENT == "F")                    %>% #-- Filter By Fail
              select(-TYP_EVENT)                          %>%
              select(ID_EVENT_F = ID_EVENT,
                     ID_CLI,
                     ID_CAMP,
                     TYP_CAMP,
                     ID_DELIVERY,
                     FAIL_DATETIME = EVENT_DATETIME,
                     FAIL_DATE = EVENT_DATE)              %>% #-- Variable Selection
              group_by(ID_CLI,
                       ID_CAMP,
                       ID_DELIVERY)                       %>% #-- Grouped By Client, Campaign & Delivery
              filter(FAIL_DATETIME == min(FAIL_DATETIME)) %>% #-- Filter By Min Mail Failed
              filter(row_number() == 1)                   %>%
              ungroup()                                   %>%
              as.data.frame()
```

We combine them in one variable:

```{r Combine Campaign Event}
campaign_event_clean_final <- df_sends                     %>%
                                left_join(df_opens,
                                          by = c("ID_CLI",
                                                 "ID_CAMP",
                                                 "ID_DELIVERY",
                                                 "TYP_CAMP"))                            %>% #-- Left Join with df_opens
                                filter(is.na(OPEN_DATE) | SEND_DATE <= OPEN_DATE)        %>%
                                left_join(df_clicks,
                                          by = c("ID_CLI",
                                                 "ID_CAMP",
                                                 "ID_DELIVERY",
                                                 "TYP_CAMP"))                            %>% #-- Left Join with df_clicks
                                filter(is.na(CLICK_DATE) | OPEN_DATE <= CLICK_DATE)      %>%
                                left_join(df_fails,
                                          by = c("ID_CLI",
                                                 "ID_CAMP",
                                                 "ID_DELIVERY",
                                                 "TYP_CAMP"))                            %>% #-- Left Join with df_fails
                                filter(is.na(FAIL_DATE) | SEND_DATE <= FAIL_DATE)        %>% 
                                mutate(OPENED = !is.na(ID_EVENT_O))                      %>% #-- Opened
                                mutate(CLICKED = !is.na(ID_EVENT_C))                     %>% #-- Clicked
                                mutate(FAILED = !is.na(ID_EVENT_F))                      %>% #-- Failed
                                mutate(DAYS_TO_OPEN = as.integer(OPEN_DATE - SEND_DATE)) %>%
                                select(ID_EVENT_S,
                                       ID_CLI,
                                       ID_CAMP,
                                       TYP_CAMP,
                                       ID_DELIVERY,
                                       SEND_DATE,
                                       OPENED,
                                       OPEN_DATE,
                                       DAYS_TO_OPEN,
                                       NUM_OPENs,
                                       CLICKED,
                                       CLICK_DATE,
                                       NUM_CLICKs,
                                       FAILED)                                                #-- Variable Selection
```

### Explanatory Analysis

```{r Summaries Campaign Event}
df6_overview <- campaign_event_clean_final %>% 
                  summarise(MIN_DATE = min(SEND_DATE),           #-- Min Date
                            MAX_DATE = max(SEND_DATE),           #-- Max Date
                            TOT_EVENTs = n_distinct(ID_EVENT_S), #-- Number of Total Events
                            TOT_CLIs = n_distinct(ID_CLI))       #-- Number of Total Clicks

knitr::kable(df6_overview)
```

Below there's a general overview about the type of campaign variable (`TYP_CAMP`):

```{r Distribution TYP_CAMP Campaign Event}
df6_overviewbytyp <- campaign_event_clean_final %>%
                        group_by(TYP_CAMP)      %>%                    #-- Grouped By TYP_CAMP
                        summarize(MIN_DATE = min(SEND_DATE),           #-- Min Date
                                  MAX_DATE = max(SEND_DATE),           #-- Max Date
                                  TOT_EVENTs = n_distinct(ID_EVENT_S), #-- Number of Total Events
                                  TOT_CLIs = n_distinct(ID_CLI))       #-- Number of Total Clicks

knitr::kable(df6_overviewbytyp)

ggplot(data = df6_overviewbytyp,
       aes(x = TYP_CAMP,
           y = TOT_EVENTs)) +    #-- Dataset to Plot
  geom_bar(stat = "identity",
           fill = "steelblue") + #-- Bar Plot
  theme_minimal()                #-- ggplot Theme
```

Below there's a general overview about the variable `OPENED`:

```{r Distribution OPENED Campaign Event}
df6_dist_opened <- campaign_event_clean_final                        %>%
                      group_by(OPENED)                               %>%
                      summarize(TOT_EVENTs = n_distinct(ID_EVENT_S),              #-- Number of Total Events
                                TOT_CLIs = n_distinct(ID_CLI))       %>%          #-- Number of Total Clicks                  
                      mutate(TYP_CAMP = 'ALL')                       %>%
                      mutate(PERCENT_EVENTs = TOT_EVENTs/df6_overview$TOT_EVENTs, #-- Percent
                             PERCENT_CLIs = TOT_CLIs/df6_overview$TOT_CLIs)       #-- Percent

knitr::kable(df6_dist_opened)

ggplot(data = df6_dist_opened,
         aes(fill = OPENED,
             x = TYP_CAMP,
             y = TOT_EVENTs)) +   #-- Data to Plot
    geom_bar(stat = "identity",
             position = "fill") + #-- Bar Plot
    theme_minimal()               #-- ggplot Theme
```

Below there's a general overview about the type of campaign variable opened (`TYP_CAMP`):

```{r Distribution OPENED by TYP_CAMP Campaign Event}
df6_dist_openedbytyp <- campaign_event_clean_final                         %>%
                          group_by(TYP_CAMP, OPENED)                       %>% #-- Grouped By TYP_CAMP & OPENED
                          summarize(TOT_EVENTs = n_distinct(ID_EVENT_S),
                                    TOT_CLIs = n_distinct(ID_CLI))         %>% #-- Number of Total Events & Client
                          left_join(df6_overviewbytyp %>%
                                      select(TYP_CAMP,
                                             ALL_TOT_EVENTs = TOT_EVENTs,
                                             ALL_TOT_CLIs = TOT_CLIs),
                                    by = 'TYP_CAMP')                       %>% #-- Left Join with df6_overviewbytyp
                          mutate(PERCENT_EVENTs = TOT_EVENTs/ALL_TOT_EVENTs,
                                 PERCENT_CLIs = TOT_CLIs/ALL_TOT_CLIs)     %>% #-- Percent
                          select(TYP_CAMP,
                                 OPENED,
                                 TOT_EVENTs,
                                 TOT_CLIs,
                                 PERCENT_EVENTs,
                                 PERCENT_CLIs)                                 #-- Variable Selection

knitr::kable(df6_dist_openedbytyp)

ggplot(data = df6_dist_openedbytyp,
       aes(fill = OPENED,
           x = TYP_CAMP,
           y = TOT_EVENTs)) +       #-- Data to Plot
  geom_bar(stat = "identity") +     #-- Bar Plot
  theme_minimal()                   #-- ggplot Theme

ggplot(data = df6_dist_openedbytyp,
       aes(fill = OPENED,
           x = TYP_CAMP,
           y = TOT_EVENTs)) +       #-- Data to Plot
  geom_bar(position = "fill",
           stat = "identity") +     #-- Bar Plot
  theme_minimal()                   #-- ggplot Theme
```

Below there's a general overview about the days after an email is opened (`DAYS_TO_OPEN`):

```{r Distribution DAYS_TO_OPEN Campaign Event}
df6_dist_daystoopen <- campaign_event_clean_final                                 %>%
                          filter(OPENED)                                          %>%
                          group_by(ID_CLI)                                        %>% #-- Grouped By ID_CLI
                          summarise(AVG_DAYS_TO_OPEN = floor(mean(DAYS_TO_OPEN))) %>% #-- Mean Day to Open
                          ungroup()                                               %>%
                          group_by(AVG_DAYS_TO_OPEN)                              %>% #-- Grouped By AVG_DAYS_TO_OPEN
                          summarise(TOT_CLIs = n_distinct(ID_CLI))

knitr::kable(head(df6_dist_daystoopen))

ggplot(data = df6_dist_daystoopen %>%
         filter(AVG_DAYS_TO_OPEN < 14),
       aes(x = AVG_DAYS_TO_OPEN,
           y = TOT_CLIs)) +             #-- Data to Plot
  geom_bar(stat = "identity",
           fill = "steelblue") +        #-- Bar Plot
  theme_minimal()                       #-- ggplot Theme
```

Below there's a general overview about the days after an email is opened (`DAYS_TO_OPEN`):

```{r Distribution AVG_DAYS_TO_OPEN Campaign Event}
df6_dist_daystoopen_vs_cumulate <- df6_dist_daystoopen          %>%
                                      arrange(AVG_DAYS_TO_OPEN) %>%
                                      mutate(PERCENT_COVERED = cumsum(TOT_CLIs)/sum(TOT_CLIs))

ggplot(data = df6_dist_daystoopen_vs_cumulate %>%
         filter(AVG_DAYS_TO_OPEN < 14),
       aes(x = AVG_DAYS_TO_OPEN,
           y = PERCENT_COVERED)) +                #-- Data to Plot
  geom_line() +
  geom_point() +                                  #-- Bar Plot
  theme_minimal() +                               #-- ggplot theme
  labs(title = "Average Days to Open a Mail",
       x     = "Average Days to Open",
       y     = "Percent Covered") +               #-- Labs
  theme(plot.title = element_text(hjust = 0.5)) + #-- Centering Title
  scale_x_continuous(breaks = seq(0, 14, 2),
                     minor_breaks = 0:14)         #-- Scale X
```

Below there's a general overview about the days after an email is clicked:

```{r Distribution CLICKED by TYP_CAMP Campaign Event}
df6_dist_clickedbytyp <- campaign_event_clean_final                      %>%
                            group_by(TYP_CAMP,
                                     CLICKED)                            %>% #-- Grouped By TYP_CAMP & CLICKED
                            summarize(TOT_EVENTs = n_distinct(ID_EVENT_S),
                                      TOT_CLIs = n_distinct(ID_CLI))     %>% #-- Number of Total Event & Client
                            left_join(df6_overviewbytyp                  %>%
                                        select(TYP_CAMP,
                                               ALL_TOT_EVENTs = TOT_EVENTs,
                                               ALL_TOT_CLIs = TOT_CLIs),
                                      by='TYP_CAMP')                     %>% #-- Left Join with df6_overviewbytyp
                            mutate(PERCENT_EVENTs = TOT_EVENTs/ALL_TOT_EVENTs,
                                   PERCENT_CLIs = TOT_CLIs/ALL_TOT_CLIs) %>% #-- Percent
                            select(TYP_CAMP,
                                   CLICKED,
                                   TOT_EVENTs,
                                   TOT_CLIs,
                                   PERCENT_EVENTs,
                                   PERCENT_CLIs)                             #-- Variable Selection

knitr::kable(df6_dist_clickedbytyp)

ggplot(data = df6_dist_clickedbytyp,
       aes(fill = CLICKED,
           x = TYP_CAMP,
           y = TOT_EVENTs)) +   #-- Data to Plot
  geom_bar(stat = "identity") + #-- Bar Plot
  theme_minimal()               #-- ggplot Theme

ggplot(data = df6_dist_clickedbytyp,
       aes(fill = CLICKED,
             x = TYP_CAMP,
             y = TOT_EVENTs)) + #-- Data to Plot
  geom_bar(position = "fill",
           stat = "identity") + #-- Bar Plot
  theme_minimal()               #-- ggplot Theme

```

Below there's a general overview about the days after an email is failed:

```{r Distribution Campaign Event}
df6_dist_failedbytyp <- campaign_event_clean_final                     %>%
                          group_by(TYP_CAMP,
                                   FAILED)                             %>% #-- Grouped By TYP_CAMP & FAILED
                          summarize(TOT_EVENTs = n_distinct(ID_EVENT_S),
                                    TOT_CLIs = n_distinct(ID_CLI))     %>% #-- Number of Total Client & Events
                          left_join(df6_overviewbytyp                  %>%
                                      select(TYP_CAMP,
                                             ALL_TOT_EVENTs = TOT_EVENTs,
                                             ALL_TOT_CLIs = TOT_CLIs),
                                    by = 'TYP_CAMP')                   %>% #-- Left Join with df6_overviewbytyp
                          mutate(PERCENT_EVENTs = TOT_EVENTs/ALL_TOT_EVENTs,
                                 PERCENT_CLIs = TOT_CLIs/ALL_TOT_CLIs) %>% #-- Percent
                          select(TYP_CAMP,
                                 FAILED,
                                 TOT_EVENTs,
                                 TOT_CLIs,
                                 PERCENT_EVENTs,
                                 PERCENT_CLIs)                             #-- Variable Selection

knitr::kable(df6_dist_failedbytyp)

ggplot(data = df6_dist_failedbytyp,
       aes(fill = FAILED,
           x = TYP_CAMP,
           y = TOT_EVENTs)) +   #-- Data to Plot
  geom_bar(stat = "identity") + #-- Bar Plot
  theme_minimal()               #-- ggplot Theme

ggplot(data = df6_dist_failedbytyp,
       aes(fill = FAILED,
           x = TYP_CAMP,
           y = TOT_EVENTs)) +   #-- Data to Plot
  geom_bar(position = "fill",   
           stat = "identity") + #-- Bar Plot
  theme_minimal()               #-- ggplot Theme
```

Below there's a general overview about the number of clicks opening an email:

```{r Distribution NUM_OPENs Campaign Event}
df6_dist_numopens <- campaign_event_clean_final                  %>%
                      group_by(NUM_OPENs)                        %>% #-- Grouped By NUM_OPENs
                      summarize(TOT_ID = n_distinct(ID_EVENT_S)) %>% #-- Number of Total Event
                      mutate(PERCENT = TOT_ID/sum(TOT_ID))       %>% #-- Percent
                      arrange(desc(PERCENT))                         #-- Sort By Percent

df6_dist_numopens

ggplot(data = df6_dist_numopens,
       aes(x = NUM_OPENs,
           y = TOT_ID)) +        #-- Data to Plot
  geom_bar(stat = "identity",
           fill = "steelblue") + #-- Bar Plot
  xlim(0, 15) +                  #-- X Limit
  theme_minimal()                #-- ggplot Theme
```

Below there's a general overview about the number of clicks in the email:

```{r Distribution NUM_CLICKs Campaign Event}
df6_dist_numclicks <- campaign_event_clean_final                   %>%
                        group_by(NUM_CLICKs)                       %>% #-- Grouped By NUM_CLICKs
                        summarize(TOT_ID = n_distinct(ID_EVENT_S)) %>% #-- Number of Total Event
                        mutate(PERCENT = TOT_ID/sum(TOT_ID))       %>% #-- Percent
                        arrange(desc(PERCENT))                         #-- Sort By Percent


knitr::kable(head(df6_dist_numclicks))

ggplot(data = df6_dist_numclicks,
       aes(x = NUM_CLICKs,
           y = TOT_ID)) +        #-- Data to Plot
  geom_bar(stat = "identity",
           fill = "steelblue") + #-- Bar Plot
  xlim(0, 15) +                  #-- X Limit
  theme_minimal()                #-- ggplot Theme
```

## 7. Purchase and Refund

Let's format dates and times and factorize `DIREZIONE`:

```{r Manipulation Tickets}
tickets_clean <- tickets_clean %>%
                    mutate(TIC_DATETIME = as.POSIXct(DATETIME,
                                                     format = "%Y-%m-%dT%H%M%S")) %>% #-- Date Time
                    mutate(TIC_HOUR = hour(TIC_DATETIME))                         %>% #-- In Hours
                    mutate(TIC_DATE = as.Date(TIC_DATETIME))                      %>% #-- In Date
                    select(-DATETIME)                                             %>% #-- Removed DATETIME
                    mutate(DIREZIONE = as.factor(DIREZIONE))                      %>% #-- Factorization
                    mutate(COD_REPARTO = as.factor(COD_REPARTO))                      #-- Factorization
```

### Reshaping

```{r Reshaping Tickets}
tickets_clean <- tickets_clean %>%
                    #-- adding day characterization
                    mutate(TIC_DATE_WEEKDAY = wday(TIC_DATE))               %>% #-- WeekDay
                    mutate(TIC_DATE_HOLIDAY = isHoliday("Italy", TIC_DATE)) %>% #-- Type of Day
                    mutate(TIC_DATE_TYP = case_when(
                      (TIC_DATE_WEEKDAY %in% c(6,7)) ~ "weekend",
                      (TIC_DATE_HOLIDAY == TRUE) ~ "holiday",
                      (TIC_DATE_WEEKDAY < 7) ~ "weekday",
                      TRUE ~ "other"))
```

### Explanatory Analysis

Let's take a general overiew about the `TIC_DATE` variable:

```{r Distribution TIC_DATE Tickets}
df7_overview <- tickets_clean %>% 
                  summarise(MIN_DATE = min(TIC_DATE),            #-- Min Date
                            MAX_DATE = max(TIC_DATE),            #-- Max Date
                            TOT_TICs = n_distinct(ID_SCONTRINO), #-- Number of Total Tickets
                            TOT_CLIs = n_distinct(ID_CLI))       #-- Number of Total Clients

knitr::kable(df7_overview)
```

Let's take a general overiew about the `DIREZIONE` variable:

```{r Distribution DIREZIONE Tickets}
df7_dist_direction <- tickets_clean %>%
                        group_by(DIREZIONE)                            %>%    #-- Group By Purchases
                        summarise(TOT_TICs = n_distinct(ID_SCONTRINO),
                                  TOT_CLIs = n_distinct(ID_CLI))       %>%    #-- Number of Total Clients & Tickets
                        mutate(PERCENT_TICs = TOT_TICs/df7_overview$TOT_TICs, #-- Percentual
                               PERCENT_CLIs = TOT_CLIs/df7_overview$TOT_CLIs)

knitr::kable(df7_dist_direction)
```

Let's take a general overiew about the `TIC_HOURS` variable:

```{r Distribution TIC_HOURS Tickets}
df7_dist_hour <- tickets_clean %>%
                    group_by(TIC_HOUR, DIREZIONE)                  %>% #-- Grouped By Hours & Purchases
                    summarise(TOT_TICs = n_distinct(ID_SCONTRINO),
                              TOT_CLIs = n_distinct(ID_CLI))       %>% #-- Number of Total Clients & Tickets
                    left_join(df7_dist_direction                   %>% #-- Left Join with df7_dist_direction
                                select(DIREZIONE,
                                       ALL_TOT_TICs = TOT_TICs,
                                       ALL_TOT_CLIs = TOT_CLIs),
                              by = 'DIREZIONE')                    %>%
                    mutate(PERCENT_TICs = TOT_TICs/ALL_TOT_TICs,
                           PERCENT_CLIs = TOT_CLIs/ALL_TOT_CLIs)   %>% #-- #-- Percentual
                    select(-ALL_TOT_TICs,
                           -ALL_TOT_CLIs)

knitr::kable(head(df7_dist_hour))

#-- TIC_HOURS
ggplot(data = df7_dist_hour,
       aes(fill = DIREZIONE,
           x = TIC_HOUR,
           y = TOT_TICs)) +                      #-- Data to Plot
  geom_bar(stat = "identity") +                  #-- Bar Plot
  labs(title = "Total Purchase per Hour",
       x     = "Hours",
       y     = "Total Amount") +                  #-- Labs
  theme_minimal() +                               #-- ggplot Theme
  theme(plot.title = element_text(hjust = 0.5)) + #-- Centering Title
  scale_fill_manual(name = "Direction",
                    labels = c("Refund", "Purchase"),
                    values = c("#D34E24", "#064789"))

#-- TIC_HOURS Percent
ggplot(data = df7_dist_hour,
       aes(fill = DIREZIONE,
           x = TIC_HOUR,
           y = TOT_TICs)) +      #-- Data to Plot
  geom_bar(stat = "identity",
           position = "fill" ) + #-- Bar Plot
  theme_minimal()                #-- ggplot Theme
```

Let's take a general overiew about the `COD_REPARTO` variable:

```{r Distribution COD_REPARTO Tickets}
df7_dist_dep <- tickets_clean                                  %>%
                  group_by(COD_REPARTO, DIREZIONE)             %>% #-- Grouped By COD_REPARTO & Purchases
                  summarize(TOT_TICs = n_distinct(ID_SCONTRINO),
                            TOT_CLIs = n_distinct(ID_CLI))     %>% #-- Number of Total Clients & Tickets
                  left_join(df7_dist_direction                 %>%
                              select(DIREZIONE,
                                     ALL_TOT_TICs = TOT_TICs,
                                     ALL_TOT_CLIs = TOT_CLIs),
                            by = 'DIREZIONE')                  %>% #-- Left Join with df7_dist_direction
                  mutate(PERCENT_TICs = TOT_TICs/ALL_TOT_TICs,
                         PERCENT_CLIs = TOT_CLIs/ALL_TOT_CLIs) %>% #-- Percent
                    select(-ALL_TOT_TICs, -ALL_TOT_CLIs)
    
knitr::kable(head(df7_dist_dep))

#-- COD_REPARTO
ggplot(data = df7_dist_dep,
       aes(fill = DIREZIONE,
           x = COD_REPARTO,
           y = TOT_TICs)) +     #-- Data to Plot
  geom_bar(stat = "identity") + #-- Bar Plot
  theme_minimal()               #-- ggplot Theme

#-- COD_REPARTO Percent
ggplot(data = df7_dist_dep,
       aes(fill = DIREZIONE,
           x = COD_REPARTO,
           y = TOT_TICs)) +      #-- Data to Plot
  geom_bar(stat = "identity",
           position = "fill" ) + #-- Bar Plot
  theme_minimal()                #-- ggplot Theme
```

Let's take a general overiew about the `TIC_DATE_TYP` variable:

```{r Distribution TIC_DATE_TYP Tickets}
df7_dist_datetyp <- tickets_clean                                  %>%
                      group_by(TIC_DATE_TYP, DIREZIONE)            %>% #-- Grouped By Type of Date & Purchases
                      summarize(TOT_TICs = n_distinct(ID_SCONTRINO),
                                TOT_CLIs = n_distinct(ID_CLI))     %>% #-- Number of Total Clients & Tickets
                      left_join(df7_dist_direction                 %>%
                                  select(DIREZIONE,
                                         ALL_TOT_TICs = TOT_TICs,
                                         ALL_TOT_CLIs = TOT_CLIs),
                                by = 'DIREZIONE')                  %>% #-- Left Join with df7_dist_direction
                      mutate(PERCENT_TICs = TOT_TICs/ALL_TOT_TICs,
                             PERCENT_CLIs = TOT_CLIs/ALL_TOT_CLIs) %>% #-- Percent
                      select(-ALL_TOT_TICs, -ALL_TOT_CLIs)

knitr::kable(df7_dist_datetyp)

#-- TIC_DATE_TYP
ggplot(data = df7_dist_datetyp,
       aes(fill = DIREZIONE,
           x = TIC_DATE_TYP,
           y = TOT_TICs)) +    #-- Data to Plot
 geom_bar(stat = "identity") + #-- Bar Plot
 theme_minimal()               #-- ggplot Theme

#-- TIC_DATE_TYP Percent
ggplot(data = df7_dist_datetyp,
       aes(fill = DIREZIONE,
           x = TIC_DATE_TYP,
           y = TOT_TICs)) +      #-- Data to Plot
  geom_bar(stat = "identity",
           position = "fill" ) + #-- Bar Plot
  theme_minimal()                #-- ggplot Theme
```

Let's take a general overiew about the `IMPORTO_LORDO` variable:

```{r Distribution IMPORTO_LORDO Tickets}
df7_dist_importosconto <- tickets_clean                       %>%
                            group_by(ID_SCONTRINO, DIREZIONE) %>% #-- Grouped By Tickets & Purchases
                            summarize(IMPORTO_LORDO = sum(IMPORTO_LORDO),
                                      SCONTO = sum(SCONTO))   %>% #-- Number of of Total Purchase 
                            ungroup()                         %>%
                            as.data.frame()

df7_dist_avgimportosconto <- df7_dist_importosconto %>%
                                group_by(DIREZIONE) %>%                            #-- Grouped By Purchases
                                summarize(AVG_IMPORTO_LORDO = mean(IMPORTO_LORDO), #-- Total Average Purchase
                                AVG_SCONTO = mean(SCONTO))

knitr::kable(df7_dist_avgimportosconto)

#-- IMPORTO_LORDO
ggplot(data = df7_dist_importosconto %>%
         filter((IMPORTO_LORDO > -1000) & (IMPORTO_LORDO < 1000)),
       aes(color = DIREZIONE,
           x = IMPORTO_LORDO)) + #-- Data to Plot
  geom_histogram(binwidth = 10,
                 fill = "white",
                 alpha = 0.5) +  #-- Histogram
  theme_minimal()                #-- ggplot Theme

#-- IMPORTO_LORDO Percent
ggplot(data = df7_dist_importosconto %>%
         filter((SCONTO > -250) & (IMPORTO_LORDO < 250)),
       aes(color = DIREZIONE, x = SCONTO)) + #-- Data to Plot
  geom_histogram(binwidth = 10,
                 fill = "white",
                 alpha = 0.5) +              #-- Histogram
  theme_minimal()                            #-- ggplot Theme
```

Let's take a general overiew about the average `IMPORTO_LORDO` variable:

```{r Distribution Average IMPORTO_LORDO Tickets}
df7_dist_importosconto_cod_rep <- tickets_clean %>%
                                    group_by(COD_REPARTO, DIREZIONE) %>% #-- Grouped By COD_REPARTO & Purchases
                                    summarize(IMPORTO_LORDO = sum(IMPORTO_LORDO),
                                              SCONTO = sum(SCONTO)) %>%  #-- Number of Total Purchase
                                    ungroup() %>%
                                    as.data.frame()

knitr::kable(head(df7_dist_importosconto_cod_rep))

#-- IMPORTO_LORDO
ggplot(data = df7_dist_importosconto_cod_rep,
       aes(fill = DIREZIONE,
           x = COD_REPARTO,
           y = IMPORTO_LORDO)) + #-- Data to Plot
 geom_bar(stat = "identity") +   #-- Bar Plot
 theme_minimal()                 #-- ggplot Theme

#-- SCONTO
ggplot(data = df7_dist_importosconto_cod_rep,
       aes(fill = DIREZIONE,
           x = COD_REPARTO,
           y = SCONTO)) +      #-- Data to Plot
 geom_bar(stat = "identity") + #-- Bar Plot
 theme_minimal()               #-- ggplot Theme
```

Let's take a general overiew about the `ID_ARTICOLO` variable:

```{r Distribution ID_ARTICOLO}
tickets_clean$ID_ARTICOLO <- as.factor(tickets_clean$ID_ARTICOLO)

df7_dist_id_articolo <- tickets_clean                                       %>%
                          filter(DIREZIONE == 1)                            %>% #-- Only Purchases
                          group_by(ID_ARTICOLO)                             %>% #-- Grouped By Items
                          summarize(NUM_VENDITE = n_distinct(ID_SCONTRINO)) %>% #-- Number of Total Tickets
                          ungroup()                                         %>%
                          as.data.frame()                                   %>%
                          arrange(desc(NUM_VENDITE))

knitr::kable(head(df7_dist_id_articolo))
```

Let's take a general overiew about the average `ID_CLIENTE` variable:

```{r Distribution Average ID_CLIENTE Tickets}
df7_dist_importosconto_id_cli <- tickets_clean                      %>%
                                    filter(DIREZIONE == 1)          %>% #-- Only Purchases
                                    group_by(ID_CLI)                %>% #-- Grouped By Clients
                                    summarize(IMPORTO_LORDO = sum(IMPORTO_LORDO),
                                              SCONTO = sum(SCONTO)) %>% #-- Number of Total Purchase
                                    ungroup()                       %>%
                                    as.data.frame()                 %>%
                                    arrange(desc(IMPORTO_LORDO))

knitr::kable(head(df7_dist_importosconto_id_cli))
```

Let's plot the Total Purchase Distribution:

```{r Distribution Total Purchase Tickets}
df7_dist_tot_purch <- tickets_clean %>%
                        filter(DIREZIONE == 1)                             %>% #-- Only Purchases
                        group_by(ID_CLI)                                   %>% #-- Grouped By Clients
                        summarise(TOT_PURCHASE = n_distinct(ID_SCONTRINO)) %>% #-- Number of Total Purchase
                        arrange(desc(TOT_PURCHASE))                            #-- Sorted By Total Purchase

knitr::kable(head(df7_dist_tot_purch))
```

Let's plot the Total Purchase Curve:

```{r Next Purchase Curve Tickets, eval = FALSE}
#-- Days for Next Purchase Curve
data_for_next_purchase <- tickets_clean %>%
                            filter(DIREZIONE == 1) %>% #-- Only Purchases
                            select(ID_CLI,
                                   ID_ARTICOLO,
                                   TIC_DATE,
                                   DIREZIONE)      %>% #-- Variable Selection
                            arrange(ID_CLI)

data_for_next_purchase

df_np <- data_for_next_purchase %>%
  group_by(ID_CLI) %>%
  mutate(Diff = TIC_DATE - lag(TIC_DATE))

x <- as.data.frame(table(df_np$Diff))
x <- x[-1, ]
x$Perc <- x$Freq/sum(x$Freq)

ggplot(x, 
       aes(x = as.numeric(Var1),
           y = cumsum(Perc))) +
  labs(title = "Next Purchase Curve",
       x = "Last Purchase Date (in Days)",
       y = "Cumulative Percent") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +    #-- Centering Title
  scale_x_continuous(breaks = seq(0, 400, 25)) +     #-- Scale X
  geom_vline(xintercept = 75, linetype = "dotted") +
  geom_line(size = 1)
```

# RFM Model

Recency, Frequency and *Monetary* value is a marketing analysis tool used to identify a company's or an organization's best customers by using certain measures.
The RFM model is based on three quantitative factors:

* *Recency*: How recently a customer has made a purchase;
* *Frequency*: How often a customer makes a purchase;
* *Monetary* Value: How much money a customer spends on purchases.

The output of the RFM model is primarily used to differentiate the marketing actions accros the customer base. 
Typical applications are:

* Investing more in marketing care actions for the best customers;
* Identifying the most cost efficcient marketing actions to increase the value of medium-value customers;
* Save budget on marketing actions for low-value customers.

These three factors can be used to reasonably predict how likely (or unlikely) it is that a customer will do business again with a firm or, in the case of a charitable organization, make another donation. [^1]

[^1]: [Investopedia.com](https://www.investopedia.com/terms/r/rfm-recency-frequency-monetary-value.asp)

Let's take as active clients if the last purchase is after *01/01/2019*:

```{r RFM Study Period}
rfm_study_period <- tickets_clean %>%
                      filter(TIC_DATE > as.Date("01/01/2019",
                                                format = "%d/%m/%Y")) #-- Active Clients

knitr::kable(head(rfm_study_period))
```

## Recency

The more recently a customer has made a purchase with a company, the more likely he or she will continue to keep the business and brand in mind for subsequent purchases.
Compared with customers who have not bought from the business in months or even longer periods, the likelihood of engaging in future transactions with recent customers is arguably higher.

Such information can be used to remind recent customers to revisit the business soon to continue meeting their purchase needs.
In an effort not to overlook lapsed customers, marketing efforts could be made to remind them that it has been a while since their last transaction while offering them an incentive to rekindle their patronage.

```{r RFM Recency}
rfm_recency <- rfm_study_period %>%
                  filter(DIREZIONE == 1) %>% #-- Only Purchases
                  group_by(ID_CLI)       %>% #-- Grouped By Clients
                  summarise(LAST_PURCHASE_DATE = max(TIC_DATE))

rfm_recency$RECENCY <- difftime(as.Date("30/04/2019",
                                        format = "%d/%m/%Y"),        #-- Recency
                                     rfm_recency$LAST_PURCHASE_DATE,
                                units = "days")

knitr::kable(head(rfm_recency))
```

We divided the type of recency in 3 different group:

* `Low`: below the 25th percentile of the distribution;
* `Medium`: from 25th to 75th percentile;
* `High`: above 75th percentile;

```{r RFM Recency Classes}
rfm_recency <- within(rfm_recency,
                 REC_CLASS <- cut(as.numeric(rfm_recency$RECENCY),
                                  breaks = quantile(rfm_recency$RECENCY,
                                                    probs = c(0, .25, .75, 1)), #-- Quantiles
                                  include.lowest = T,
                                  labels = c("low", "medium", "high")))         #-- Classes

rec_label <- as.data.frame(table(rfm_recency$REC_CLASS))

ggplot(data = rec_label,
       aes(x = Var1, y = Freq,
           fill = Freq)) +                        #-- Dataset to Plot
  geom_bar(stat = "identity") +                   #-- Bar Plot
  labs(title = "Recency Distribution",
       x     = "Recency Classes",
       y     = "Total Purchase") +                #-- Labs
  theme_minimal() +                               #-- ggplot Theme
  theme(plot.title = element_text(hjust = 0.5)) + #-- Centering Title
  scale_x_discrete(labels = c("Low", "Medium", "High")) + 
  guides(fill = FALSE)
```

## Frequency

The frequency of a customer’s transactions may be affected by factors such as the type of product, the price point for the purchase, and the need for replenishment or replacement. If the purchase cycle can be predicted, for example when a customer needs to buy new groceries, marketing efforts could be directed towards reminding them to visit the business when items such as eggs or milk have been depleted.

```{r RFM Frequency}
rfm_frequency <- rfm_study_period                                      %>%
                    filter(DIREZIONE == 1)                             %>% #-- Only Purchases
                    group_by(ID_CLI)                                   %>% #-- Grouped By Clients
                    summarise(TOT_PURCHASE = n_distinct(ID_SCONTRINO)) %>%
                    arrange(desc(TOT_PURCHASE))

knitr::kable(head(rfm_frequency))
```

We divided the type of recency in 3 different group:

* `Low`: below 2 total purchases;
* `Medium`: from 2 to 5 purchases;
* `High`: above 5 (to 101) purchases;

```{r RFM Frequency Classes}
rfm_frequency <- within(rfm_frequency,
                   FREQ_CLASS <- cut(rfm_frequency$TOT_PURCHASE,
                                     breaks = c(0, 2, 5, 101),             #-- Break of Classes
                                     include.lowest = T,
                                     right = F,
                                     labels = c("low", "medium", "high"))) #-- Classes

table(rfm_frequency$FREQ_CLASS)

freq_label <- as.data.frame(table(rfm_frequency$FREQ_CLASS))

ggplot(data = freq_label,
       aes(x = Var1, y = Freq,
           fill = Freq)) +                        #-- Dataset to Plot
  geom_bar(stat = "identity") +                   #-- Bar Plot
  labs(title = "Frequency Distribution",
       x     = "Frequency Classes",
       y     = "Total Purchase") +                #-- Labs
  theme_minimal() +                               #-- ggplot Theme
  theme(plot.title = element_text(hjust = 0.5)) + #-- Centering Title
  scale_x_discrete(labels = c("Low", "Medium", "High")) + 
  guides(fill = FALSE)
```

## Monetary

Monetary value stems from the lucrativeness of expenditures the customer makes with the business during their transactions. A natural inclination is to put more emphasis on encouraging customers who spend the most money to continue to do so. While this can produce a better return on investment in marketing and customer service, it also runs the risk of alienating customers who have been consistent but have not spent as much with each transaction.

```{r RFM Monetary}
rfm_monetary <- rfm_study_period                            %>%
                  filter(DIREZIONE == 1)                    %>% #-- Only Purchases
                  group_by(ID_CLI)                          %>% #-- Grouped By Clients
                  summarize(IMPORTO_LORDO = sum(IMPORTO_LORDO),
                            SCONTO = sum(SCONTO),
                            SPESA = IMPORTO_LORDO - SCONTO) %>%
                  ungroup()                                 %>%
                  as.data.frame()                           %>%
                  arrange(desc(IMPORTO_LORDO))

knitr::kable(head(rfm_monetary))
```

We divided the type of recency in 3 different group:

* `Low`: below 2 total purchases;
* `Medium`: from 2 to 5 purchases;
* `High`: above 5 (to 101) purchases;

```{r RFM Monetary Classes}
rfm_monetary <- within(rfm_monetary,
                   MON_CLASS <- cut(rfm_monetary$SPESA,
                                    breaks = quantile(rfm_monetary$SPESA,
                                                      probs = c(0, .25, .75, 1)),
                                    include.lowest = T,
                                    labels = c("low", "medium", "high"))) #-- Classes

table(rfm_monetary$MON_CLASS)

mon_label <- as.data.frame(table(rfm_monetary$MON_CLASS))

ggplot(data = mon_label,
       aes(x = Var1, y = Freq,
           fill = Freq)) +                        #-- Dataset to Plot
  geom_bar(stat = "identity") +                   #-- Bar Plot
  scale_colour_brewer(palette = "Spectral") +
  labs(title = "Monetary Distribution",
       x     = "Monetary Classes",
       y     = "Total Amount") +                  #-- Labs
  theme_minimal() +                               #-- ggplot Theme
  theme(plot.title = element_text(hjust = 0.5)) + #-- Centering Title
  scale_x_discrete(labels = c("Low", "Medium", "High")) + 
  guides(fill = FALSE)
```

## Merge

We merge all three RFM dataset in one:

```{r RFM Merge}
rfm <- merge(rfm_frequency, #-- Frequency
             rfm_monetary,  #-- Monetary
             by = "ID_CLI") #-- Key for Merge

rfm <- merge(rfm,           #-- Frequency + Monetary
             rfm_recency,   #-- Recency
             by = "ID_CLI") #-- Key for Merge

knitr::kable(head(rfm[ , c("ID_CLI", "REC_CLASS", "FREQ_CLASS", "MON_CLASS")]))
```

The recency and frequency percentilr groups are combined to define new classes describing the customer loyalty status:

```{r RF Dataset}
rfm$RF <- NA

for(i in c(1:nrow(rfm))){
  if(rfm$REC_CLASS[i] == "low" && rfm$FREQ_CLASS[i] == "low") rfm$RF[i] <- "One-Timer"
  if(rfm$REC_CLASS[i] == "medium" && rfm$FREQ_CLASS[i] == "low") rfm$RF[i] <- "One-Timer"
  if(rfm$REC_CLASS[i] == "high" && rfm$FREQ_CLASS[i] == "low") rfm$RF[i] <- "Leaving"
  if(rfm$REC_CLASS[i] == "low" && rfm$FREQ_CLASS[i] == "medium") rfm$RF[i] <- "Engaged"
  if(rfm$REC_CLASS[i] == "medium" && rfm$FREQ_CLASS[i] == "medium") rfm$RF[i] <- "Engaged"
  if(rfm$REC_CLASS[i] == "high" && rfm$FREQ_CLASS[i] == "medium") rfm$RF[i] <- "Leaving"
  if(rfm$REC_CLASS[i] == "low" && rfm$FREQ_CLASS[i] == "high") rfm$RF[i] <- "Top"
  if(rfm$REC_CLASS[i] == "medium" && rfm$FREQ_CLASS[i] == "high") rfm$RF[i] <- "Top"
  if(rfm$REC_CLASS[i] == "high" && rfm$FREQ_CLASS[i] == "high") rfm$RF[i] <- "Leaving Top"
}

table(rfm$RF)
```

Let's plot the variable `RF`:

```{r RF Plot}
rf_df <- as.data.frame(rbind(c("Top",         "High",   "Low",    16248),
                              c("Top",         "High",   "Medium", 16248),
                              c("Leaving Top", "High",   "High",   592),
                              c("Engaged",     "Medium", "Low",    36316),
                              c("Engaged",     "Medium", "Medium", 36316),
                              c("Leaving",     "Medium", "High",   27187),
                              c("One Timer",   "Low",    "Low",    32763),
                              c("One Timer",   "Low",    "Medium", 32763),
                              c("Leaving",     "Low",    "High",   27187)))

colnames(rf_df) <-  c("Level", "Frequency", "Recency", "Value")
rf_df$Frequency <- factor(rf_df$Frequency,
                          levels = c("High", "Medium", "Low"))
rf_df$Recency <- factor(rf_df$Recency,
                          levels = c("High", "Medium", "Low"))
rf_df$Value <- as.numeric(rf_df$Value)

ggplot(rf_df, aes(x = Frequency, y = Recency, fill = Value)) + 
  geom_tile() +
  geom_text(aes(label = Level)) +
  scale_fill_distiller(palette = "Spectral") +
  theme_minimal()

rf <- as.data.frame(table(rfm$RF))
rf

ggplot(data = rf,
       aes(x = Var1, y = Freq,
           fill = Freq)) +                        #-- Dataset to Plot
  geom_bar(stat = "identity") +                   #-- Bar Plot
  scale_colour_brewer(palette = "Spectral") +
  labs(title = "RF Distribution",
       x     = "RF Classes",
       y     = "Total Clients") +                 #-- Labs
  theme_minimal() +                               #-- ggplot Theme
  theme(plot.title = element_text(hjust = 0.5)) + #-- Centering Title
  scale_x_discrete(labels = c("Engaged", "Leaving", "Leaving Top",
                              "One Timer", "Top")) + 
  guides(fill = FALSE)
```

Finally, the RFM classe are obtained combining the RF classes with the Monetary groups

```{r RFM Dataset}
rfm$RFM <- NA

for(i in c(1:nrow(rfm))){
  if(rfm$RF[i] == "One-Timer" && rfm$MON_CLASS[i] == "low") rfm$RFM[i] <- "Cheap"
  if(rfm$RF[i] == "Leaving" && rfm$MON_CLASS[i] == "low") rfm$RFM[i] <- "Tin"
  if(rfm$RF[i] == "Engaged" && rfm$MON_CLASS[i] == "low") rfm$RFM[i] <- "Copper"
  if(rfm$RF[i] == "Leaving Top" && rfm$MON_CLASS[i] == "low") rfm$RFM[i] <- "Bronze"
  if(rfm$RF[i] == "Top" && rfm$MON_CLASS[i] == "low") rfm$RFM[i] <- "Silver"
  
  if(rfm$RF[i] == "One-Timer" && rfm$MON_CLASS[i] == "medium") rfm$RFM[i] <- "Tin"
  if(rfm$RF[i] == "Leaving" && rfm$MON_CLASS[i] == "medium") rfm$RFM[i] <- "Copper"
  if(rfm$RF[i] == "Engaged" && rfm$MON_CLASS[i] == "medium") rfm$RFM[i] <- "Bronze"
  if(rfm$RF[i] == "Leaving Top" && rfm$MON_CLASS[i] == "medium") rfm$RFM[i] <- "Silver"
  if(rfm$RF[i] == "Top" && rfm$MON_CLASS[i] == "medium") rfm$RFM[i] <- "Gold"
  
  if(rfm$RF[i] == "One-Timer" && rfm$MON_CLASS[i] == "high") rfm$RFM[i] <- "Copper"
  if(rfm$RF[i] == "Leaving" && rfm$MON_CLASS[i] == "high") rfm$RFM[i] <- "Bronze"
  if(rfm$RF[i] == "Engaged" && rfm$MON_CLASS[i] == "high") rfm$RFM[i] <- "Silver"
  if(rfm$RF[i] == "Leaving Top" && rfm$MON_CLASS[i] == "high") rfm$RFM[i] <- "Gold"
  if(rfm$RF[i] == "Top" && rfm$MON_CLASS[i] == "high") rfm$RFM[i] <- "Diamond"
}
```

Let's plot the RFM matrix

```{r RFM Plot}
rfm_df <- as.data.frame(rbind(c("Top", "High", "Diamond", 10984),
                             c("Top", "Medium", "Gold", 5585),
                             c("Top", "Low", "Silver", 10306),
                             c("Leaving Top", "High", "Gold", 5585),
                             c("Leaving Top", "Medium", "Silver", 10306),
                             c("Leaving Top", "Low", "Bronze", 25932),
                             c("Engaged", "High", "Silver", 10306),
                             c("Engaged", "Medium", "Bronze", 25932),
                             c("Engaged", "Low", "Copper", 20938),
                             c("Leaving", "High", "Bronze", 25932),
                             c("Leaving", "Medium", "Copper", 20938),
                             c("Leaving", "Low", "Tin", 24967),
                             c("One Timer", "High", "Copper", 20938),
                             c("One Timer", "Medium", "Tin", 24967),
                             c("One Timer", "Low", "Cheap", 14394)))

colnames(rfm_df) <- c("RF", "Monetary", "Level", "Value")
rfm_df$RF <- factor(rfm_df$RF,
                    levels = c("Top", "Leaving Top",
                               "Engaged", "Leaving", "One Timer"))
rfm_df$Monetary <- factor(rfm_df$Monetary,
                          levels = c("Low", "Medium", "High"))
rfm_df$Value <- as.numeric(rfm_df$Value)

ggplot(rfm_df, aes(x = RF, y = Monetary, fill = Value)) + 
  geom_tile() +
  geom_text(aes(label = Level)) +
  scale_fill_distiller(palette = "Spectral") +
  theme_minimal()

rfm_plot <- as.data.frame(table(rfm$RFM))

ggplot(data = rfm_plot,
       aes(x = Var1, y = Freq,
           fill = Freq)) +                        #-- Dataset to Plot
  geom_bar(stat = "identity") +                   #-- Bar Plot
  scale_colour_brewer(palette = "Spectral") +
  labs(title = "RFM Distribution",
       x     = "RFM Classes",
       y     = "Total Clients") +                 #-- Labs
  theme_minimal() +                               #-- ggplot Theme
  theme(plot.title = element_text(hjust = 0.5)) + #-- Centering Title
  scale_x_discrete(labels = c("Bronze", "Cheap", "Copper", "Diamond",
                              "Gold", "Silver", "Tin")) + 
  guides(fill = FALSE)
```

```{r RFM Save, eval = FALSE, include = FALSE}
save(rfm, rfm_monetary, rfm_recency, rfm_frequency, file = "rfm.RData")
```

# Churn

*Churn* rate, when applied to a customer base, refers to the proportion of contractual customers or subscribers who leave a supplier during a given time period.

Churn is directly related to the profitability of a company.
The more some can learn about customer behaviors, the more profit can be gained.
This also helps identifying and improving areas or fields where customer service is lacking.

This aims can be achieved by developing a propensity supervised model:

1. choosing a reference date in the past:

```{r Reference Date Churn}
#-- Reference Date: 01/01/2019
churn_study_period <- tickets_clean %>%
                        filter(DIREZIONE == 1,
                               TIC_DATE < as.Date("1/1/2019",
                                                  format = "%d/%m/%Y"),
                               TIC_DATE > as.Date("01/10/2018",
                                                  format = "%d/%m/%Y"))

knitr::kable(head(churn_study_period))
```

2. Imposing the length (frequencey of the distribution and/or the purchase time scale) of an holdout period after each reference date:

```{r Holdout Period Churn}
#-- Holdout Period: 28/02/2019
churn_holdout <- tickets_clean %>%
                  filter(DIREZIONE == 1,
                         TIC_DATE < as.Date("28/02/2019",
                                            format = "%d/%m/%Y"),
                         TIC_DATE > as.Date("01/01/2019",
                                            format = "%d/%m/%Y"))

no_churner <- unique(churn_holdout$ID_CLI)

knitr::kable(head(churn_holdout))
```

3. Choosing the lenght of a lookback period before the reference date:

```{r Lookback Period Churn}
#-- Lookback Period: 3 months

#-- Recency to Merge
churn_recency <- churn_study_period %>%
                  filter(DIREZIONE == 1) %>%
                  group_by(ID_CLI) %>%
                  summarise(LAST_PURCHASE_DATE = max(TIC_DATE))

churn_recency$RECENCY <- difftime(as.Date("01/01/2019",
                                          format = "%d/%m/%Y"),          #-- Recency
                                  churn_recency$LAST_PURCHASE_DATE,
                                  units = "days")

#-- Frequency to Merge
churn_frequency <- churn_study_period %>%
                    filter(DIREZIONE == 1) %>%
                    group_by(ID_CLI) %>%
                    summarise(TOT_PURCHASE = n_distinct(ID_SCONTRINO)) %>%
                    arrange(desc(TOT_PURCHASE))

#-- Monetary to Merge
churn_monetary <- churn_study_period %>%
                    filter(DIREZIONE == 1) %>%
                    group_by(ID_CLI) %>%
                    summarize(IMPORTO_LORDO = sum(IMPORTO_LORDO),
                              SCONTO = sum(SCONTO),
                              SPESA = IMPORTO_LORDO - SCONTO) %>%
                    ungroup() %>%
                    as.data.frame() %>%
                    arrange(desc(IMPORTO_LORDO))

churn <- merge(churn_recency, churn_frequency, by = "ID_CLI")
churn <- merge(churn, churn_monetary, by = "ID_CLI") %>%
          select(ID_CLI,
                 RECENCY,
                 SPESA, 
                 TOT_PURCHASE)

knitr::kable(head(churn))
```

4. Assigning to each customer a target 0/1 variable such that 1 is assigned to customers who churned in the holout period:

```{r Assign to Churn}
churn$CHURN <- 1

for (i in c(1:nrow(churn))){
  if (churn$ID_CLI[i] %in% no_churner) churn$CHURN[i] <- 0
}

churn$CHURN <- as.factor(churn$CHURN)

table(churn$CHURN)
```

5. Defining a set of potentially relevant predictors variables to be computed within the lookback period:

* RECENCY;
* SPESA;
* TOT_PURCHASE;
* REGION;
* LAST_COD_FID;
* TYP_JOB.

```{r Adding Interesting Variables Churn}
churn <- left_join(churn, account_clean[, c("ID_CLI", "TYP_JOB")], by = "ID_CLI")  #-- Add Type Job
churn <- left_join(churn, fidelity_clean[, c("ID_CLI", "LAST_COD_FID")], by = "ID_CLI") #-- Add Type of Fidelity Card
region <- left_join(account_clean[, c("ID_CLI", "ID_ADDRESS")],
                    address_clean[, c("ID_ADDRESS", "REGION")], by = "ID_ADDRESS") #-- Add Region
churn <- left_join(churn, region, by = "ID_CLI")
churn <- churn[, -8]

knitr::kable(head(churn))
```

### Model

First, it's necessary to split the entire dataset in Train and Test.



```{r Train Test Split}
churn <- na.omit(churn)

train_index <- createDataPartition(churn$CHURN, 
                                   p = .70, 
                                   list = FALSE, 
                                   times = 1)

#-- Train Test Split
train <- churn[train_index,]
test <- churn[-train_index,]

table(train$CHURN)
```

Models to evaluate:

* Recursive Partitioning And Regression Trees (`tree`);
* Random Forest (`tree_rf`);
* Logistic Regression (`logistic`);
* Lasso (`lasso`).

### Regression Trees

```{r Tree}
tree <- rpart(CHURN ~ RECENCY + SPESA + TOT_PURCHASE + REGION + TYP_JOB,
              data = train)

rpart.plot(tree, extra = "auto")

summary(tree) #-- num di acquisti è la variabile più importante
printcp(tree) #-- complexity parameter
```

### Random Forest

```{r Random Forest}
memory.limit(100000)

tree_rf <- randomForest(CHURN ~ RECENCY + SPESA + TOT_PURCHASE + REGION + TYP_JOB,
                        data = train, ntree = 100)
print(tree_rf)
```

### Logistic Regression

```{r Logistic}
logistic <- train(CHURN ~ RECENCY + SPESA + TOT_PURCHASE + REGION + TYP_JOB,
                 data = train,
                 method = "glm")

summary(logistic)
```

### Lasso

```{r Lasso}
lasso <- train(CHURN ~ RECENCY + SPESA + TOT_PURCHASE + REGION + TYP_JOB,
            data = train,
            method = "glmnet",
            family = "binomial")

lasso
plot(lasso)
```

## Prediction

```{r Prediction Treee}
pred <- predict(tree, test[, -5], type = "class")
p1 <- unlist(pred)
confusionMatrix(p1, test$CHURN)
```

```{r Prediction RF}
pred_rf <- predict(tree_rf, test[,-5], type = "class")
confusionMatrix(pred_rf, test$CHURN)
```

```{r Prediction Logistic}
pred_logistic <- predict(logistic, test[, -5], type = "raw")
confusionMatrix(pred_logistic, test$CHURN)
```

```{r Prediction Lasso}
pred_lasso <- predict(lasso, test[,-5], type = "raw")
confusionMatrix(pred_lasso, test$CHURN)
```

```{r Accuracy CHURN}
accuracy <- as.data.frame(t(cbind(confusionMatrix(pred_lasso, test$CHURN)$overall[1],
      confusionMatrix(pred_logistic, test$CHURN)$overall[1],
      confusionMatrix(pred_rf, test$CHURN)$overall[1],
      confusionMatrix(pred, test$CHURN)$overall[1])))

accuracy <- as.data.frame(cbind(c("Lasso", "Logistic","Random Forest","Tree"),
                                accuracy))

colnames(accuracy) <- c("Models", "Accuracy")

ggplot(data = accuracy,
       aes(x = Models,
           y = Accuracy,
           fill = Models)) +
  geom_bar(stat = "identity") +
  coord_cartesian(ylim = c(0.681, 0.693)) +
  theme_minimal() +
  guides(fill = FALSE) +
  labs(title = "Accuracy",
       x = "Models",
       y = " ") +
  scale_fill_manual(values = c("#FF1053","#6C6EA0","#66C7F4","#C1CAD6")) +
  theme(plot.title = element_text(hjust = 0.5)) + #-- Centering Title

plot(accuracy$Accuracy)
```

## Assessment

```{r Lift}
#-- Probability
p_tree = predict(tree, test[,-5], "prob")[,1]
p_rf = predict(tree_rf, test[,-5], "prob")[,1]
p_log = predict(logistic, test[,-5], "prob")[,1]
p_lasso = predict(lasso, test[,-5], "prob")[,1]

#-- Data Frame
data_class = as.data.frame(cbind(p_tree, p_rf, p_log, p_lasso))
data_class = cbind(data_class, test$CHURN)
colnames(data_class) <- c("p_tree", "p_rf", "p_log", "p_lasso", "churn")
head(data_class)

#-- Lift
lift_tree = gain_lift(data = data_class, score = 'p_tree', target = 'churn')
lift_rf = gain_lift(data = data_class, score = 'p_rf', target = 'churn')
lift_log = gain_lift(data = data_class, score = 'p_log', target = 'churn')
lift_lasso = gain_lift(data = data_class, score = 'p_lasso', target = 'churn')

#-- tree non ha senso, mentre ha senso utilizzare rf e log (lasso è praticamente uguale al logistico)
```

## Score

```{r Score sul Futuro}
#-- Reference Date: 01/01/2019
new_churn_study_period <- tickets_clean %>%
                        filter(DIREZIONE == 1,
                               TIC_DATE < as.Date("30/04/2019",
                                                  format = "%d/%m/%Y"),
                               TIC_DATE > as.Date("01/02/2019",
                                                  format = "%d/%m/%Y"))

#-- Recency to Merge
new_churn_recency <- new_churn_study_period %>%
                  filter(DIREZIONE == 1) %>%
                  group_by(ID_CLI) %>%
                  summarise(LAST_PURCHASE_DATE = max(TIC_DATE))

new_churn_recency$RECENCY <- difftime(as.Date("30/04/2019",
                                          format = "%d/%m/%Y"),          #-- Recency
                                  new_churn_recency$LAST_PURCHASE_DATE,
                                  units = "days")

#-- Frequency to Merge
new_churn_frequency <- new_churn_study_period %>%
                    filter(DIREZIONE == 1) %>%
                    group_by(ID_CLI) %>%
                    summarise(TOT_PURCHASE = n_distinct(ID_SCONTRINO)) %>%
                    arrange(desc(TOT_PURCHASE))

#-- Monetary to Merge
new_churn_monetary <- new_churn_study_period %>%
                    filter(DIREZIONE == 1) %>%
                    group_by(ID_CLI) %>%
                    summarise(IMPORTO_LORDO = sum(IMPORTO_LORDO),
                              SCONTO = sum(SCONTO),
                              SPESA = IMPORTO_LORDO - SCONTO) %>%
                    ungroup() %>%
                    as.data.frame() %>%
                    arrange(desc(IMPORTO_LORDO))

new_churn <- merge(new_churn_recency, new_churn_frequency, by = "ID_CLI")
new_churn <- merge(new_churn, new_churn_monetary, by = "ID_CLI") %>%
          select(ID_CLI,
                 RECENCY,
                 SPESA, 
                 TOT_PURCHASE)

knitr::kable(head(new_churn))

new_churn <- left_join(new_churn, account_clean[, c("ID_CLI", "TYP_JOB")],
                       by = "ID_CLI")  #-- Add Type Job

new_churn <- left_join(new_churn, fidelity_clean[, c("ID_CLI", "LAST_COD_FID")],
                       by = "ID_CLI") #-- Add Type of Fidelity Card

region <- left_join(account_clean[, c("ID_CLI", "ID_ADDRESS")],
                    address_clean[, c("ID_ADDRESS", "REGION")],
                    by = "ID_ADDRESS") #-- Add Region

new_churn <- left_join(new_churn, region, by = "ID_CLI")
new_churn <- new_churn[, -7]

knitr::kable(head(new_churn))

new_churn <- na.omit(new_churn)

new_churn$prob_to_churn <- predict(logistic, new_churn, type = "prob")[,2]
knitr::kable(head(new_churn))
```

## Market Basket Analysis

Market Basket Analysis is one of the key techniques used by large retailers to uncover associations between items.
It works by looking for combinations of items that occur together frequently in transactions.
To put it another way, it allows retailers to identify relationships between the items that people buy.

Association Rules are widely used to analyze retail basket or transaction data, and are intended to identify strong rules discovered in transaction data using measures of interestingness, based on the concept of strong rules. [^2]

[^2]: [Datascienceplus.com](https://datascienceplus.com/a-gentle-introduction-on-market-basket-analysis%E2%80%8A-%E2%80%8Aassociation-rules/)

```{r Best Sellers}
count_tickets <- tickets_clean %>%
  group_by(ID_ARTICOLO) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  slice_max(count, n = 100)

count_tickets %>%
  slice_max(count, n = 10) %>%
  ggplot(aes(x = reorder(ID_ARTICOLO, count), y = count)) +
  geom_bar(stat= "identity", fill = "#FF1053") +
  coord_flip() + 
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) + #-- Centering Title
  labs(x = "Article",
       y = "Total Purchase",
       title = "Top 10 Best Sellers")
```

```{r Association Rule}
tickets_ordered <- tickets_clean[order(tickets_clean$ID_CLI),]

itemList <- plyr::ddply(tickets_clean, c("ID_CLI", "TIC_DATE"),
                         function(df1)paste(df1$ID_ARTICOLO, 
                       collapse = ","))

itemList$ID_ARTICOLO <- NULL
itemList$TIC_DATE <- NULL
colnames(itemList) <- c("items")

write.csv(itemList, file.path(data_dir, "market_basket.csv"),
          quote = FALSE, row.names = TRUE)
```

```{r Read Transaction}
tr <- arules::read.transactions('market_basket.csv', format = 'basket', sep=',')

tr
summary(tr)
```


```{r Item Frequency Rules}
itemFrequencyPlot(tr, topN = 20, type = 'absolute')

rules <- apriori(tr, parameter = list(supp = 0.001, conf = 0.8))
rules <- sort(rules, by = 'confidence', decreasing = TRUE)
summary(rules)

inspect(rules)
```

```{r Plots}
topRules <- rules[1:10]
plot(topRules)

plot(topRules, method = "graph")
```

